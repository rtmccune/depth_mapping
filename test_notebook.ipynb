{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing.image_utils import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dir = '/home/rmccune/depth_mapping/CB03_all_photos/test_segs'\n",
    "labels_dir = '/home/rmccune/depth_mapping/CB03_all_photos/test_labls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating labels from predictions:   0%|          | 0/137 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating labels from predictions: 100%|██████████| 137/137 [00:17<00:00,  7.85it/s]\n"
     ]
    }
   ],
   "source": [
    "create_labels_from_predsegs(preds_dir, labels_dir, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating labels from predictions: 100%|██████████| 137/137 [00:18<00:00,  7.57it/s]\n"
     ]
    }
   ],
   "source": [
    "create_labels_from_predsegs(preds_dir, labels_dir, use_gpu=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate Water Levels into separate csvs per flood event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the abbreviated flood events and full data records\n",
    "abbr_flood_events = pd.read_csv('/home/rmccune/depth_mapping/CB_03_flood_record/abbr_flood_events.csv')\n",
    "flood_events = pd.read_csv('/home/rmccune/depth_mapping/CB_03_flood_record/flood_events.csv')\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = 'output_flood_events'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created CSV files in 'output_flood_events' directory.\n"
     ]
    }
   ],
   "source": [
    "# Convert the start and end time columns to datetime\n",
    "abbr_flood_events['start_time_UTC'] = pd.to_datetime(abbr_flood_events['start_time_UTC'], utc=True)\n",
    "abbr_flood_events['end_time_UTC'] = pd.to_datetime(abbr_flood_events['end_time_UTC'], utc=True)\n",
    "\n",
    "# Format datetime to string for folder naming\n",
    "abbr_flood_events['start_time_str'] = abbr_flood_events['start_time_UTC'].dt.strftime('%Y%m%d%H%M%S')\n",
    "abbr_flood_events['end_time_str'] = abbr_flood_events['end_time_UTC'].dt.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "# Iterate over each unique flood event in the abbreviated events\n",
    "for _, row in abbr_flood_events.iterrows():\n",
    "    flood_event_number = row['flood_event']\n",
    "    start_time_utc = row['start_time_str']\n",
    "    end_time_utc = row['end_time_str']\n",
    "    \n",
    "    sensor_id = row['sensor_ID']\n",
    "    \n",
    "    # Filter the full flood events DataFrame for the current flood event number\n",
    "    filtered_events = flood_events[flood_events['flood_event'] == flood_event_number]\n",
    "    \n",
    "    # Generate a filename based on start_time_UTC and end_time_UTC\n",
    "    filename = f\"{sensor_id}_{start_time_utc}_{end_time_utc}.csv\"\n",
    "    \n",
    "    # Save the filtered DataFrame to a new CSV file\n",
    "    filtered_events.to_csv(os.path.join(output_dir, filename), index=False)\n",
    "\n",
    "print(f\"Successfully created CSV files in '{output_dir}' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move csvs into proper subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files have been moved to their corresponding subfolders.\n"
     ]
    }
   ],
   "source": [
    "# Define the main directory where the output CSV files are located\n",
    "main_directory = 'output_flood_events'\n",
    "# Define the parent directory where you want to create subfolders\n",
    "parent_directory = '/home/rmccune/depth_mapping/CB03_all_photos/flood_events'  # Change this to your actual parent directory\n",
    "\n",
    "# Iterate over the files in the main directory\n",
    "for filename in os.listdir(main_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extract the folder name from the filename (without the .csv extension)\n",
    "        folder_name = filename[:-4]  # Remove '.csv' from the filename\n",
    "        \n",
    "        # Create the full path for the subfolder\n",
    "        subfolder_path = os.path.join(parent_directory, folder_name)\n",
    "        \n",
    "        # Create the subfolder if it doesn't exist\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "        \n",
    "        # Move the CSV file to the corresponding subfolder\n",
    "        source_path = os.path.join(main_directory, filename)\n",
    "        destination_path = os.path.join(subfolder_path, filename)\n",
    "        shutil.move(source_path, destination_path)\n",
    "\n",
    "print(\"CSV files have been moved to their corresponding subfolders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cupy as cp\n",
    "import cupyx as cpx\n",
    "import time\n",
    "import cv2\n",
    "import zarr\n",
    "\n",
    "# from gpu_acc_utils import *\n",
    "from cupyx.scipy.interpolate import RegularGridInterpolator as reg_interp\n",
    "from cupyx.scipy.ndimage import binary_closing\n",
    "from cupyx.scipy.ndimage import label\n",
    "from skimage.measure import find_contours\n",
    "import image_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/rmccune/depth_mapping/data/lidar/Job1051007_34077_04_88.laz'\n",
    "\n",
    "min_x_extent = 712160\n",
    "max_x_extent = 712230\n",
    "min_y_extent = 33100\n",
    "max_y_extent = 33170\n",
    "\n",
    "grid_gen = image_processing.GridGenerator(file_path, min_x_extent, max_x_extent, min_y_extent, max_y_extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory to store grids already exists: generated_grids\n"
     ]
    }
   ],
   "source": [
    "resolution = 0.05 # meters\n",
    "\n",
    "pts_array = grid_gen.create_point_array()\n",
    "grid_x, grid_y, grid_z = grid_gen.gen_grid(resolution, z=pts_array)\n",
    "\n",
    "grid_z_gpu = cp.asarray(grid_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing.depth_mapper import DepthMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_directory_path = '/home/rmccune/depth_mapping/CB03_all_photos/flood_events/CB_03_20220615012935_20220615024735/zarr/labels_rects'\n",
    "zarr_store_path = '/home/rmccune/depth_mapping/CB03_all_photos/flood_events/CB_03_20220615012935_20220615024735/zarr/depth_maps_95th_ponding_OOP'\n",
    "\n",
    "mapper = DepthMapper(grid_z_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper.process_depth_maps(zarr_directory_path, zarr_store_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_acc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
